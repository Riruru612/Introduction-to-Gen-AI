{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKdkSxTQ55qY"
      },
      "source": [
        "**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HmgRIbF4W5V",
        "outputId": "dd1a7f13-f008-41ac-c8b4-d4d0e5be4700"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKcCUv6K6I3V"
      },
      "source": [
        "**Importing all the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T66n1d2K4zBt",
        "outputId": "d086bd6f-3ef9-4579-9d8e-f06dcb65e959"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuFz5oqE6OeW"
      },
      "source": [
        "**Preparing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRTnx3ad46z5",
        "outputId": "24f33a5b-b9d6-4b93-d937-4ecb00cbe79a"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/cat_species\"\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(0.3, 0.3, 0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "full_dataset = datasets.ImageFolder(DATASET_PATH, transform=train_transform)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "print(\"Total classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwy5geWt6Wl6"
      },
      "source": [
        "**Train-Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7yJYzGgy49zl"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QinBtIEK6Z-U"
      },
      "source": [
        "**Channel Attention Module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zF7Tbi5M5IpV"
      },
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // reduction, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels // reduction, channels, 1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.fc(self.avg(x)) + self.fc(self.max(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWy59U2E7u0-"
      },
      "source": [
        "**Residual Block**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O7LpAtHb7R7c"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_c),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_c)\n",
        "        )\n",
        "\n",
        "        self.att = ChannelAttention(out_c)\n",
        "        self.shortcut = nn.Conv2d(in_c, out_c, 1) if in_c != out_c else nn.Identity()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = out * self.att(out)\n",
        "        out += self.shortcut(x)\n",
        "        return self.relu(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntziqK5u7xyF"
      },
      "source": [
        "**Custom CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yvDlvxzZ7Tep"
      },
      "outputs": [],
      "source": [
        "class StrongCustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = ResidualBlock(3, 64)\n",
        "        self.layer2 = ResidualBlock(64, 128)\n",
        "        self.layer3 = ResidualBlock(128, 256)\n",
        "        self.layer4 = ResidualBlock(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.layer1(x))\n",
        "        x = self.pool(self.layer2(x))\n",
        "        x = self.pool(self.layer3(x))\n",
        "        x = self.pool(self.layer4(x))\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YiTyEZeN5dDE"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return 100 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "njZp0SFK5eX7"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=20):\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, patience=3, factor=0.5\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        val_acc = evaluate(model, val_loader)\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    return val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFTkn0UI749e"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntJeRkc_5fqY",
        "outputId": "85abb281-096e-4d6d-9987-94d776d4ef8a"
      },
      "outputs": [],
      "source": [
        "baseline_model = StrongCustomCNN(num_classes).to(device)\n",
        "baseline_acc = train_model(baseline_model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTWQ7dKY8Evl"
      },
      "source": [
        "**Zero-Shot-Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5SblJKdw5ik1"
      },
      "outputs": [],
      "source": [
        "def zero_shot_accuracy(loader):\n",
        "    model = models.resnet18(pretrained=True).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(device)\n",
        "            preds = model(x).argmax(1)\n",
        "            correct += (preds >= 281).sum().item()  # ImageNet cat classes\n",
        "            total += x.size(0)\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "zero_shot_acc = zero_shot_accuracy(val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3_5RWFo78DW"
      },
      "source": [
        "**Few Shot Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K_xp3qVr5kqw"
      },
      "outputs": [],
      "source": [
        "def create_few_shot_dataset(dataset, shots=5):\n",
        "    class_map = {i: [] for i in range(num_classes)}\n",
        "    for idx, (_, label) in enumerate(dataset):\n",
        "        class_map[label].append(idx)\n",
        "\n",
        "    indices = []\n",
        "    for c in class_map:\n",
        "        indices.extend(random.sample(class_map[c], shots))\n",
        "\n",
        "    return Subset(dataset, indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1Zc2D0Qx5mAJ"
      },
      "outputs": [],
      "source": [
        "def few_shot_training(dataset):\n",
        "    few_data = create_few_shot_dataset(dataset)\n",
        "    few_loader = DataLoader(few_data, batch_size=16, shuffle=True)\n",
        "\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(5):\n",
        "        for x, y in few_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return evaluate(model, val_loader)\n",
        "\n",
        "few_shot_acc = few_shot_training(full_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHO2B72h8I8V"
      },
      "source": [
        "**Continue Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50AFiKL35nKG",
        "outputId": "8c129a29-5035-4b7d-e679-526a0fba8b65"
      },
      "outputs": [],
      "source": [
        "def continual_learning(dataset):\n",
        "    mid = len(dataset) // 2\n",
        "    d1, d2 = random_split(dataset, [mid, len(dataset)-mid])\n",
        "\n",
        "    l1 = DataLoader(d1, batch_size=32, shuffle=True)\n",
        "    l2 = DataLoader(d2, batch_size=32, shuffle=True)\n",
        "\n",
        "    model = StrongCustomCNN(num_classes).to(device)\n",
        "\n",
        "    train_model(model, l1, val_loader, epochs=10)\n",
        "    acc = train_model(model, l2, val_loader, epochs=8)\n",
        "\n",
        "    return acc\n",
        "\n",
        "continual_acc = continual_learning(full_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOtNDuLC8Lkk"
      },
      "source": [
        "**Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdEEaeMb5pIs",
        "outputId": "2682caf7-e0e5-418a-b14b-a453f0714e93"
      },
      "outputs": [],
      "source": [
        "print(f\"Custom CNN Accuracy      : {baseline_acc:.2f}%\")\n",
        "print(f\"Zero-Shot Accuracy       : {zero_shot_acc:.2f}%\")\n",
        "print(f\"Few-Shot Accuracy        : {few_shot_acc:.2f}%\")\n",
        "print(f\"Continual Learning Acc   : {continual_acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "snscrape-env",
      "language": "python",
      "name": "snscrape-env"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
