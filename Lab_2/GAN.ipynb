{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAyyXlZpmFJf",
        "outputId": "2e73604d-b384-482c-93c1-5eb4edc39968"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User Configuration and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IclK0n3oZvE",
        "outputId": "191f08dc-b8cd-42a5-bafd-ff86d3dbaac8"
      },
      "outputs": [],
      "source": [
        "dataset_choice = input(\"Enter dataset ('mnist' or 'fashion'): \").strip().lower()\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "noise_dim = 100\n",
        "lr = 0.0002\n",
        "save_interval = 5\n",
        "\n",
        "half_batch = batch_size // 2\n",
        "\n",
        "os.makedirs(f\"generated_samples_{dataset_choice}\", exist_ok=True)\n",
        "os.makedirs(f\"final_generated_images_{dataset_choice}\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0AGt3pQob6z",
        "outputId": "83490ea7-4e7e-48a3-e7b1-f1454ae9e563"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "if dataset_choice == \"mnist\":\n",
        "    train_set = torchvision.datasets.MNIST(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "else:\n",
        "    train_set = torchvision.datasets.FashionMNIST(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Generator and Discriminator Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xIKM2Fk7ou-Q"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z).view(-1, 1, 28, 28)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img.view(img.size(0), -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Initialization and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6-P7DG8royFW"
      },
      "outputs": [],
      "source": [
        "netG = Generator().to(device)\n",
        "netD = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generator Weight and Gradient Norm Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j4bgFNbWoz22"
      },
      "outputs": [],
      "source": [
        "def print_generator_weights_and_gradients(generator):\n",
        "    print(\"\\nGenerator Layer-wise Norms\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    for name, param in generator.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            weight_norm = param.data.norm(2).item()\n",
        "            grad_norm = param.grad.data.norm(2).item()\n",
        "            print(\n",
        "                f\"{name:<15} | \"\n",
        "                f\"Weight norm: {weight_norm:.6f} | \"\n",
        "                f\"Grad norm: {grad_norm:.6f}\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GAN Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B52tBPmbo2cs",
        "outputId": "e2550ca7-16f2-497e-c924-f683189f8365"
      },
      "outputs": [],
      "source": [
        "print(\"\\nStarting Training...\\n\")\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "\n",
        "    for real_imgs, _ in dataloader:\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        b_size = real_imgs.size(0)\n",
        "\n",
        "        real_labels = torch.ones(b_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(b_size, 1).to(device)\n",
        "\n",
        "        optimizerD.zero_grad()\n",
        "\n",
        "        output_real = netD(real_imgs)\n",
        "        loss_real = criterion(output_real, real_labels)\n",
        "\n",
        "        noise = torch.randn(b_size, noise_dim).to(device)\n",
        "        fake_imgs = netG(noise)\n",
        "        output_fake = netD(fake_imgs.detach())\n",
        "        loss_fake = criterion(output_fake, fake_labels)\n",
        "\n",
        "        loss_D = loss_real + loss_fake\n",
        "        loss_D.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        optimizerG.zero_grad()\n",
        "\n",
        "        output = netD(fake_imgs)\n",
        "        loss_G = criterion(output, real_labels)\n",
        "        loss_G.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "    d_acc = (output_real > 0.5).float().mean().item() * 100\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{epochs} | \"\n",
        "        f\"D_loss: {loss_D.item():.4f} | \"\n",
        "        f\"D_acc: {d_acc:.2f}% | \"\n",
        "        f\"G_loss: {loss_G.item():.4f}\"\n",
        "    )\n",
        "\n",
        "    print_generator_weights_and_gradients(netG)\n",
        "\n",
        "    if epoch % save_interval == 0 or epoch == 1:\n",
        "        save_image(\n",
        "            fake_imgs[:25],\n",
        "            f\"generated_samples_{dataset_choice}/epoch_{epoch:03d}.png\",\n",
        "            nrow=5,\n",
        "            normalize=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Final Generated Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhPIYUuKo8N6",
        "outputId": "63a22b4f-4915-4941-8d2e-e7246bb8c00d"
      },
      "outputs": [],
      "source": [
        "print(\"\\nSaving final 100 generated images...\")\n",
        "\n",
        "netG.eval()\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(100, noise_dim).to(device)\n",
        "    samples = netG(z)\n",
        "\n",
        "    for i in range(100):\n",
        "        save_image(\n",
        "            samples[i],\n",
        "            f\"final_generated_images_{dataset_choice}/img_{i+1}.png\",\n",
        "            normalize=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va8UM7h_pHxy",
        "outputId": "af49d6a6-c7bd-4e83-b198-b4ee2aadbe9a"
      },
      "outputs": [],
      "source": [
        "torch.save(netG.state_dict(), f\"generator_{dataset_choice}.pth\")\n",
        "torch.save(netD.state_dict(), f\"discriminator_{dataset_choice}.pth\")\n",
        "\n",
        "print(\"Models saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading Generated Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20sepsDPsQnK",
        "outputId": "a5d6bb07-8ed6-4ec1-bc46-ef91c37c48eb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_name = \"mnist_gan_outputs\"\n",
        "\n",
        "files_to_zip = [\n",
        "    \"final_generated_images_mnist\",\n",
        "    \"generated_samples_mnist\",\n",
        "    \"discriminator_mnist.pth\",\n",
        "    \"generator_mnist.pth\"\n",
        "]\n",
        "\n",
        "with zipfile.ZipFile(f\"{zip_name}.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for item in files_to_zip:\n",
        "        if os.path.isdir(item):\n",
        "            for foldername, subfolders, filenames in os.walk(item):\n",
        "                for filename in filenames:\n",
        "                    file_path = os.path.join(foldername, filename)\n",
        "                    zipf.write(file_path)\n",
        "        else:\n",
        "            zipf.write(item)\n",
        "\n",
        "print(f\"{zip_name}.zip created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this experiment, a Generative Adversarial Network (GAN) was successfully trained on the MNIST and Fashion-MNIST datasets.\n",
        "\n",
        "The Generator learned to generate realistic images, while the Discriminator learned to differentiate between real and generated images. Model performance was monitored using loss values and layer-wise weight and gradient norms."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
