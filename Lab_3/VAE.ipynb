{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLC_88k3wTfg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Device Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKN8NnTPweXr"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 50\n",
        "LR = 1e-3\n",
        "LATENT_DIM = 2\n",
        "\n",
        "BASE_DIR = \"vae_comparison\"\n",
        "NO_KL_DIR = f\"{BASE_DIR}/no_kl\"\n",
        "KL_DIR = f\"{BASE_DIR}/with_kl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wVUrQBywgQY"
      },
      "outputs": [],
      "source": [
        "for d in [NO_KL_DIR, KL_DIR]:\n",
        "    os.makedirs(f\"{d}/recon\", exist_ok=True)\n",
        "    os.makedirs(f\"{d}/samples\", exist_ok=True)\n",
        "    os.makedirs(f\"{d}/models\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShyDbrNPwkQy",
        "outputId": "eecdb645-881f-4afe-aee7-4c146ae815a6"
      },
      "outputs": [],
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variational Autoencoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdPK7IWqwm8P"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.mu = nn.Linear(256, latent_dim)\n",
        "        self.logvar = nn.Linear(256, latent_dim)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        h = self.encoder(x)\n",
        "        mu = self.mu(h)\n",
        "        logvar = self.logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decoder(z)\n",
        "        return recon, mu, logvar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Function without KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BctEh71CwrWX"
      },
      "outputs": [],
      "source": [
        "def loss_no_kl(recon, x):\n",
        "    x = x.view(-1, 784)\n",
        "    return nn.functional.binary_cross_entropy(recon, x, reduction=\"sum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Function with KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QxZqRWQwvoQ"
      },
      "outputs": [],
      "source": [
        "def loss_with_kl(recon, x, mu, logvar):\n",
        "    x = x.view(-1, 784)\n",
        "    recon_loss = nn.functional.binary_cross_entropy(recon, x, reduction=\"sum\")\n",
        "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHlT_IFtww94"
      },
      "outputs": [],
      "source": [
        "def save_recon(model, loader, epoch, path):\n",
        "    model.eval()\n",
        "    x, _ = next(iter(loader))\n",
        "    x = x.to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        recon, _, _ = model(x)\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    for i in range(8):\n",
        "        plt.subplot(2,8,i+1)\n",
        "        plt.imshow(x[i][0].cpu(), cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(2,8,i+9)\n",
        "        plt.imshow(recon[i].view(28,28).cpu(), cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.savefig(f\"{path}/recon/epoch_{epoch}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qfpr54Kwy8E"
      },
      "outputs": [],
      "source": [
        "def save_samples(model, epoch, path):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(16, LATENT_DIM).to(DEVICE)\n",
        "        samples = model.decoder(z)\n",
        "\n",
        "    samples = samples.view(-1,1,28,28).cpu()\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    for i in range(16):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(samples[i][0], cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.savefig(f\"{path}/samples/epoch_{epoch}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK5K2d3Dw0id"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, use_kl, save_path):\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for x, _ in train_loader:\n",
        "            x = x.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            recon, mu, logvar = model(x)\n",
        "\n",
        "            if use_kl:\n",
        "                loss = loss_with_kl(recon, x, mu, logvar)\n",
        "            else:\n",
        "                loss = loss_no_kl(recon, x)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch} | Loss: {total_loss/len(train_loader.dataset):.4f}\")\n",
        "\n",
        "        save_recon(model, test_loader, epoch, save_path)\n",
        "        save_samples(model, epoch, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ6eUjqjw3gG"
      },
      "outputs": [],
      "source": [
        "model_no_kl = VAE(LATENT_DIM).to(DEVICE)\n",
        "model_kl = VAE(LATENT_DIM).to(DEVICE)\n",
        "\n",
        "opt_no_kl = optim.Adam(model_no_kl.parameters(), lr=LR)\n",
        "opt_kl = optim.Adam(model_kl.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Without KL Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqbUdr1bw_I1",
        "outputId": "6e15b288-250c-471c-9773-0d32693da184"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining WITHOUT KL Divergence\")\n",
        "train(model_no_kl, opt_no_kl, False, NO_KL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training With KL Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HOsWgfJxBRV",
        "outputId": "0c7d6523-1335-4767-c2a7-f58e84c4285a"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining WITH KL Divergence\")\n",
        "train(model_kl, opt_kl, True, KL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edjexM9mxCwk"
      },
      "outputs": [],
      "source": [
        "torch.save(model_no_kl.state_dict(), f\"{NO_KL_DIR}/models/model.pth\")\n",
        "torch.save(model_kl.state_dict(), f\"{KL_DIR}/models/model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latent Space Visualization Without KL Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZysHyKf0vhi"
      },
      "outputs": [],
      "source": [
        "def plot_and_save_latent_no_kl(model, loader, save_path):\n",
        "    model.eval()\n",
        "    zs, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            _, mu, _ = model(x)\n",
        "            zs.append(mu.cpu())\n",
        "            labels.append(y)\n",
        "\n",
        "    zs = torch.cat(zs)\n",
        "    labels = torch.cat(labels)\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(zs[:, 0], zs[:, 1], c=labels, cmap=\"tab10\", s=5)\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Latent Space WITHOUT KL Divergence\")\n",
        "\n",
        "    plt.savefig(f\"{save_path}/latent_space_without_kl.png\", dpi=300)\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latent Space Visualization With KL Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGL3gizS1y_w"
      },
      "outputs": [],
      "source": [
        "def plot_and_save_latent_with_kl(model, loader, save_path):\n",
        "    model.eval()\n",
        "    zs, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            _, mu, _ = model(x)\n",
        "            zs.append(mu.cpu())\n",
        "            labels.append(y)\n",
        "\n",
        "    zs = torch.cat(zs)\n",
        "    labels = torch.cat(labels)\n",
        "\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(zs[:, 0], zs[:, 1], c=labels, cmap=\"tab10\", s=5)\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Latent Space WITH KL Divergence\")\n",
        "\n",
        "    plt.savefig(f\"{save_path}/latent_space_with_kl.png\", dpi=300)\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sN4Yx9h21055",
        "outputId": "153758cb-38d4-4a85-829b-e8662d1f4e2d"
      },
      "outputs": [],
      "source": [
        "plot_and_save_latent_no_kl(model_no_kl, test_loader, NO_KL_DIR)\n",
        "plot_and_save_latent_with_kl(model_kl, test_loader, KL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the Zipped folder into yoour local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PsoaX_2121i",
        "outputId": "2ec849a5-924a-4f85-ca3a-2065202bc5b2"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "zip_name = \"vae_results\"\n",
        "folder_to_zip = \"vae_comparison\"\n",
        "\n",
        "shutil.make_archive(zip_name, 'zip', folder_to_zip)\n",
        "\n",
        "print(\"ZIP file created:\", zip_name + \".zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "KL divergence is essential for transforming an autoencoder into a generative model by enforcing a structured latent space."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
